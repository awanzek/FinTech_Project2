{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /Users/anna/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use news api to get all news articles and headline sentiment related to Covid-19 or Coronavirus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read api key environment variable\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"newsapikey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newsapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a newsapi client\n",
    "from newsapi import NewsApiClient\n",
    "newsapi = NewsApiClient(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set start and end datetimes of for 30 days allowed access to articles\n",
    "from datetime import datetime, timedelta\n",
    "end_date = datetime.now()\n",
    "start_date = end_date + timedelta(-30)\n",
    "end_date=end_date.strftime(\"%Y-%m-%d\")\n",
    "start_date=start_date.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total articles related to Covid-19: 255698\n"
    }
   ],
   "source": [
    "# Fetch the Covid19 news articles\n",
    "covid19_news = newsapi.get_everything(\n",
    "    from_param=start_date,\n",
    "    to=end_date,\n",
    "    q=\"Covid 19\",\n",
    "    language=\"en\",\n",
    "    page_size=100,\n",
    "    sort_by=\"relevancy\"\n",
    ")\n",
    "# Print number articles found for reference\n",
    "print(f\"Total articles related to Covid-19: {covid19_news['totalResults']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total articles related to Coronavirus: 259736\n"
    }
   ],
   "source": [
    "# Fetch the Coronavirus news articles\n",
    "corona_news = newsapi.get_everything(\n",
    "    from_param=start_date,\n",
    "    to=end_date,\n",
    "    q=\"coronavirus\",\n",
    "    language=\"en\",\n",
    "    page_size=100,\n",
    "    sort_by=\"relevancy\"\n",
    ")\n",
    "# Print number articles found for reference \n",
    "print(f\"Total articles related to Coronavirus: {corona_news['totalResults']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Compound  Negative  Neutral  Positive  \\\n0    0.8934     0.000    0.722     0.278   \n1    0.0772     0.000    0.966     0.034   \n2   -0.8860     0.278    0.722     0.000   \n3   -0.7717     0.193    0.807     0.000   \n4    0.6597     0.000    0.833     0.167   \n\n                                                text  \n0  Do you remember earlier this year, when people...  \n1  In addition to the tally of confirmed COVID-19...  \n2  Officials initially wanted to track the locati...  \n3  As a workplace strategist, I am constantly ask...  \n4  Our smartphones are set to play a significant ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Compound</th>\n      <th>Negative</th>\n      <th>Neutral</th>\n      <th>Positive</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.8934</td>\n      <td>0.000</td>\n      <td>0.722</td>\n      <td>0.278</td>\n      <td>Do you remember earlier this year, when people...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.0772</td>\n      <td>0.000</td>\n      <td>0.966</td>\n      <td>0.034</td>\n      <td>In addition to the tally of confirmed COVID-19...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>-0.8860</td>\n      <td>0.278</td>\n      <td>0.722</td>\n      <td>0.000</td>\n      <td>Officials initially wanted to track the locati...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>-0.7717</td>\n      <td>0.193</td>\n      <td>0.807</td>\n      <td>0.000</td>\n      <td>As a workplace strategist, I am constantly ask...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.6597</td>\n      <td>0.000</td>\n      <td>0.833</td>\n      <td>0.167</td>\n      <td>Our smartphones are set to play a significant ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Create the Covid-19 and Coronavirus combined sentiment scores DataFrame\n",
    "#covid-19 sentiment list to dataframe\n",
    "covid19_sentiment_list=[]\n",
    "for article in covid19_news[\"articles\"]:        \n",
    "   try: \n",
    "        text = article[\"content\"]\n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        scores={\"Compound\":compound, \"Negative\":neg, \"Neutral\":neu, \"Positive\":pos, \"text\":text}\n",
    "        covid19_sentiment_list.append(scores)\n",
    "        \n",
    "   except: \n",
    "        pass\n",
    "\n",
    "covid19_sentiment_df=pd.DataFrame(covid19_sentiment_list)\n",
    "covid19_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    Compound  Negative  Neutral  Positive  \\\n91    0.0000     0.000    1.000     0.000   \n92   -0.4215     0.076    0.924     0.000   \n93    0.4019     0.000    0.909     0.091   \n94    0.0000     0.000    1.000     0.000   \n95    0.6124     0.000    0.848     0.152   \n\n                                                 text  \n91  Media captionUS President Donald Trump said he...  \n92  Image caption\\r\\n Kelly Morellon (right) and h...  \n93  Image copyrightGetty ImagesImage caption\\r\\n P...  \n94  Image copyrightGetty ImagesImage caption\\r\\n T...  \n95  Image caption\\r\\n Betsi Cadwaladr health board...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Compound</th>\n      <th>Negative</th>\n      <th>Neutral</th>\n      <th>Positive</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>91</td>\n      <td>0.0000</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>Media captionUS President Donald Trump said he...</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>-0.4215</td>\n      <td>0.076</td>\n      <td>0.924</td>\n      <td>0.000</td>\n      <td>Image caption\\r\\n Kelly Morellon (right) and h...</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.4019</td>\n      <td>0.000</td>\n      <td>0.909</td>\n      <td>0.091</td>\n      <td>Image copyrightGetty ImagesImage caption\\r\\n P...</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.0000</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>Image copyrightGetty ImagesImage caption\\r\\n T...</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.6124</td>\n      <td>0.000</td>\n      <td>0.848</td>\n      <td>0.152</td>\n      <td>Image caption\\r\\n Betsi Cadwaladr health board...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Create the corona sentiment scores DataFrame\n",
    "corona_sentiment_list=[]\n",
    "for article in corona_news[\"articles\"]:        \n",
    "   try: \n",
    "        text = article[\"content\"]\n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        scores={\"Compound\":compound, \"Negative\":neg, \"Neutral\":neu, \"Positive\":pos, \"text\":text}\n",
    "        corona_sentiment_list.append(scores)\n",
    "        \n",
    "   except: \n",
    "        pass\n",
    "\n",
    "corona_sentiment_df=pd.DataFrame(corona_sentiment_list)\n",
    "corona_sentiment_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Compound  Negative  Neutral  Positive  \\\n0    0.8934     0.000    0.722     0.278   \n1    0.0772     0.000    0.966     0.034   \n2   -0.8860     0.278    0.722     0.000   \n3   -0.7717     0.193    0.807     0.000   \n4    0.6597     0.000    0.833     0.167   \n\n                                                text  \n0  Do you remember earlier this year, when people...  \n1  In addition to the tally of confirmed COVID-19...  \n2  Officials initially wanted to track the locati...  \n3  As a workplace strategist, I am constantly ask...  \n4  Our smartphones are set to play a significant ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Compound</th>\n      <th>Negative</th>\n      <th>Neutral</th>\n      <th>Positive</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.8934</td>\n      <td>0.000</td>\n      <td>0.722</td>\n      <td>0.278</td>\n      <td>Do you remember earlier this year, when people...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.0772</td>\n      <td>0.000</td>\n      <td>0.966</td>\n      <td>0.034</td>\n      <td>In addition to the tally of confirmed COVID-19...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>-0.8860</td>\n      <td>0.278</td>\n      <td>0.722</td>\n      <td>0.000</td>\n      <td>Officials initially wanted to track the locati...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>-0.7717</td>\n      <td>0.193</td>\n      <td>0.807</td>\n      <td>0.000</td>\n      <td>As a workplace strategist, I am constantly ask...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.6597</td>\n      <td>0.000</td>\n      <td>0.833</td>\n      <td>0.167</td>\n      <td>Our smartphones are set to play a significant ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "#Combine the data frames to one large Covid-19/Coronavirus Dataframe\n",
    "#use frames to join the dataframes at the last row\n",
    "frames=[covid19_sentiment_df, corona_sentiment_df]\n",
    "allcovidnews_sentiment_df=pd.concat(frames)\n",
    "allcovidnews_sentiment_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    Compound  Negative  Neutral  Positive  \\\n91    0.0000     0.000    1.000     0.000   \n92   -0.4215     0.076    0.924     0.000   \n93    0.4019     0.000    0.909     0.091   \n94    0.0000     0.000    1.000     0.000   \n95    0.6124     0.000    0.848     0.152   \n\n                                                 text  \n91  Media captionUS President Donald Trump said he...  \n92  Image caption\\r\\n Kelly Morellon (right) and h...  \n93  Image copyrightGetty ImagesImage caption\\r\\n P...  \n94  Image copyrightGetty ImagesImage caption\\r\\n T...  \n95  Image caption\\r\\n Betsi Cadwaladr health board...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Compound</th>\n      <th>Negative</th>\n      <th>Neutral</th>\n      <th>Positive</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>91</td>\n      <td>0.0000</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>Media captionUS President Donald Trump said he...</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>-0.4215</td>\n      <td>0.076</td>\n      <td>0.924</td>\n      <td>0.000</td>\n      <td>Image caption\\r\\n Kelly Morellon (right) and h...</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.4019</td>\n      <td>0.000</td>\n      <td>0.909</td>\n      <td>0.091</td>\n      <td>Image copyrightGetty ImagesImage caption\\r\\n P...</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.0000</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>Image copyrightGetty ImagesImage caption\\r\\n T...</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.6124</td>\n      <td>0.000</td>\n      <td>0.848</td>\n      <td>0.152</td>\n      <td>Image caption\\r\\n Betsi Cadwaladr health board...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "allcovidnews_sentiment_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         Compound    Negative     Neutral    Positive\ncount  193.000000  193.000000  193.000000  193.000000\nmean     0.018316    0.057306    0.879751    0.062927\nstd      0.437222    0.067422    0.092829    0.070582\nmin     -0.944200    0.000000    0.576000    0.000000\n25%     -0.361200    0.000000    0.829000    0.000000\n50%      0.000000    0.049000    0.886000    0.047000\n75%      0.361200    0.095000    0.947000    0.098000\nmax      0.893400    0.379000    1.000000    0.310000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Compound</th>\n      <th>Negative</th>\n      <th>Neutral</th>\n      <th>Positive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>count</td>\n      <td>193.000000</td>\n      <td>193.000000</td>\n      <td>193.000000</td>\n      <td>193.000000</td>\n    </tr>\n    <tr>\n      <td>mean</td>\n      <td>0.018316</td>\n      <td>0.057306</td>\n      <td>0.879751</td>\n      <td>0.062927</td>\n    </tr>\n    <tr>\n      <td>std</td>\n      <td>0.437222</td>\n      <td>0.067422</td>\n      <td>0.092829</td>\n      <td>0.070582</td>\n    </tr>\n    <tr>\n      <td>min</td>\n      <td>-0.944200</td>\n      <td>0.000000</td>\n      <td>0.576000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>25%</td>\n      <td>-0.361200</td>\n      <td>0.000000</td>\n      <td>0.829000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>50%</td>\n      <td>0.000000</td>\n      <td>0.049000</td>\n      <td>0.886000</td>\n      <td>0.047000</td>\n    </tr>\n    <tr>\n      <td>75%</td>\n      <td>0.361200</td>\n      <td>0.095000</td>\n      <td>0.947000</td>\n      <td>0.098000</td>\n    </tr>\n    <tr>\n      <td>max</td>\n      <td>0.893400</td>\n      <td>0.379000</td>\n      <td>1.000000</td>\n      <td>0.310000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Describe the  Sentiment Related to Covid19/Coronavirus\n",
    "allcovidnews_sentiment_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "\n",
    "Use NLTK to get token words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the default stopwords list if necessary\n",
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package wordnet to /Users/anna/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Complete the tokenizer function\n",
    "def tokenizer(sentiment_data):\n",
    "   # \"\"\"Tokenizes text.\"\"\"\n",
    "    tokens_list=[] \n",
    "    for row in sentiment_data['text']: \n",
    "        text_block=row\n",
    "        sentence_tokenized=sent_tokenize(text_block)\n",
    "        # Create a list of the words\n",
    "        tokenized_words=[word_tokenize(sentence) for sentence in sentence_tokenized]\n",
    "\n",
    "        # Convert the words to lowercase\n",
    "        first_result=[word.lower() for word in tokenized_words[0] if word.lower() not in stop_words]\n",
    "        #print(first_result)\n",
    "\n",
    "        # Remove the punctuation\n",
    "        second_result= [word for word in first_result if word.isalnum()]\n",
    "\n",
    "        # Remove the stop words\n",
    "        third_result= [word for word in second_result if not word in stop_words]\n",
    "\n",
    "        # Lemmatize Words into root words\n",
    "        # Instantiate the lemmatizer\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lem_words=[lemmatizer.lemmatize(word) for word in third_result]\n",
    "\n",
    "        tokens={\"token\":lem_words}\n",
    "        tokens_list.append(tokens)  \n",
    "        \n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'token': ['remember',\n  'earlier',\n  'year',\n  'people',\n  'sure',\n  'pandemic',\n  'would',\n  'end',\n  'weather',\n  'warmed']}"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "allcovid_tokens=tokenizer(allcovidnews_sentiment_df)\n",
    "allcovid_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                               token\n0  [remember, earlier, year, people, sure, pandem...\n1  [addition, tally, confirmed, case, secondary, ...\n2  [official, initially, wanted, track, location,...\n3  [workplace, strategist, constantly, asked, wor...\n4  [smartphones, set, play, significant, role, he...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>[remember, earlier, year, people, sure, pandem...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>[addition, tally, confirmed, case, secondary, ...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>[official, initially, wanted, track, location,...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>[workplace, strategist, constantly, asked, wor...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>[smartphones, set, play, significant, role, he...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Create a new tokens column for covid19/coronavirus\n",
    "from pandas import DataFrame\n",
    "allcovid_tokens_df=pd.DataFrame(allcovid_tokens)\n",
    "allcovid_tokens_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Compound  Negative  Neutral  Positive  \\\n0    0.8934     0.000    0.722     0.278   \n1    0.0772     0.000    0.966     0.034   \n2   -0.8860     0.278    0.722     0.000   \n3   -0.7717     0.193    0.807     0.000   \n4    0.6597     0.000    0.833     0.167   \n\n                                                text  \\\n0  Do you remember earlier this year, when people...   \n1  In addition to the tally of confirmed COVID-19...   \n2  Officials initially wanted to track the locati...   \n3  As a workplace strategist, I am constantly ask...   \n4  Our smartphones are set to play a significant ...   \n\n                                               token  \n0  [remember, earlier, year, people, sure, pandem...  \n1  [addition, tally, confirmed, case, secondary, ...  \n2  [official, initially, wanted, track, location,...  \n3  [workplace, strategist, constantly, asked, wor...  \n4  [smartphones, set, play, significant, role, he...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Compound</th>\n      <th>Negative</th>\n      <th>Neutral</th>\n      <th>Positive</th>\n      <th>text</th>\n      <th>token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.8934</td>\n      <td>0.000</td>\n      <td>0.722</td>\n      <td>0.278</td>\n      <td>Do you remember earlier this year, when people...</td>\n      <td>[remember, earlier, year, people, sure, pandem...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.0772</td>\n      <td>0.000</td>\n      <td>0.966</td>\n      <td>0.034</td>\n      <td>In addition to the tally of confirmed COVID-19...</td>\n      <td>[addition, tally, confirmed, case, secondary, ...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>-0.8860</td>\n      <td>0.278</td>\n      <td>0.722</td>\n      <td>0.000</td>\n      <td>Officials initially wanted to track the locati...</td>\n      <td>[official, initially, wanted, track, location,...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>-0.7717</td>\n      <td>0.193</td>\n      <td>0.807</td>\n      <td>0.000</td>\n      <td>As a workplace strategist, I am constantly ask...</td>\n      <td>[workplace, strategist, constantly, asked, wor...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.6597</td>\n      <td>0.000</td>\n      <td>0.833</td>\n      <td>0.167</td>\n      <td>Our smartphones are set to play a significant ...</td>\n      <td>[smartphones, set, play, significant, role, he...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# Create a new tokens column for covid19/coronavirus and join to sentiment df\n",
    "allcovidnews_sentiment_df=pd.concat([allcovidnews_sentiment_df,allcovid_tokens_df], axis=1, join=\"inner\")\n",
    "allcovidnews_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGrams and Frequency Analysis\n",
    "\n",
    "Find top 5 words related to covid19 and coronavirus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'token': ['remember',\n  'earlier',\n  'year',\n  'people',\n  'sure',\n  'pandemic',\n  'would',\n  'end',\n  'weather',\n  'warmed']}"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "allcovid_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to make list of dictionarys containing strings as values into one big string\n",
    "#get list of all tokens as a single string for covid-19 and coronavirus articles\n",
    "allcovid_big_token_list=[]\n",
    "for dictionary in allcovid_tokens:\n",
    "    allcovid_big_token_list.extend(dictionary['token'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_count(token_list): \n",
    "    # Make all articles in the text to one single string\n",
    "    bigrams = ngrams(token_list, n=2)\n",
    "    top_5 = dict(Counter(bigrams).most_common(5))\n",
    "    return list(top_5.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(('char', 'image'), 25),\n (('coronavirus', 'pandemic'), 13),\n (('image', 'copyrightgetty'), 13),\n (('chat', 'u'), 11),\n (('u', 'facebook'), 11)]"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Generate the Covid-19/Coronavirus N-grams where N=2\n",
    "ngram_count(allcovid_big_token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using token_count function to generate top 5 words related to covid/corona news\n",
    "def token_count(token_list, N=5):\n",
    "    \"\"\"Returns the top N tokens from the frequency count\"\"\"\n",
    "    # Combine all articles in corpus into one large string\n",
    "    return Counter(token_list).most_common(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('char', 67),\n ('coronavirus', 63),\n ('image', 49),\n ('caption', 37),\n ('pandemic', 35)]"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Get the top 5 words for Covid19/Coronavirus\n",
    "allcovid_top5=token_count(allcovid_big_token_list,N=5)\n",
    "allcovid_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}